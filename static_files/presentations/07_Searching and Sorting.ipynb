{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11n5gndbRzoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Searching and Sorting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Searching\n",
    "\n",
    "2. Hashing\n",
    "\n",
    "3. Sorting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.2 Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will now turn our attention to some of the most common problems that arise in computing, those of <u>searching</u> and <u>sorting</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9ehxkHHJ14K",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Searching is the algorithmic process of finding a particular item in a collection of items. A search typically returns either `True` or `False` when queried on whether an item is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In Python, there is a very easy way to ask whether an item is in a list of items. We use the `in` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "15 in [3, 5, 2, 4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "3 in [3, 5, 2, 4, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Even though this is easy to write, an underlying process must be carried out to answer the question. It turns out that there are many different ways to search for the item!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.3 The Sequential Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When data items are stored in a collection such as a list, we say that they have a linear or sequential relationship. The relative positions can be access using the index values of the individual items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since these index values are ordered, it is possible for us to visit them in sequence. This process gives rise to our first search technique, the <u>sequential search</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/seqsearch.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following function needs two items – the list and the item we are looking for – and returns a Boolean value as to whether it is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sequential_search(a_list, item):\n",
    "    pos = 0\n",
    "\n",
    "    while pos < len(a_list):\n",
    "        if a_list[pos] == item:\n",
    "            return True\n",
    "        pos = pos + 1\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "test_list = [54, 26, 93, 17, 77, 31, 44, 55, 20, 65]\n",
    "print(sequential_search(test_list, 44))\n",
    "print(sequential_search(test_list, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.3.1 Analysis of Sequential Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To analyze searching algorithms, we need to decide on a basic unit of computation. For searching, it makes sense to count the number of comparisons performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzEFrClyJ14N",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another assumption is that the probability that the item we are looking for is in any particular position is exactly the same for each position of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If the item is **not in the list**, the only way to know that is to compare it against every item present. If there are $n$ \n",
    " items, then the sequential search requires $n$ comparisons to discover that the item is not there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are three different scenarios that can occur if the item is in the list. In the best case we will find the item in the first place we look, at the beginning of the list. We will need only one comparison. In the worst case, we will not discover the item until the very last comparison, the $n$-th comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On average, we will find the item about half way into the list; that is, we will compare against $\\frac{n}{2}$ items. So the complexity of the sequential search is $O(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V5fNcKnJ14N",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What would happen to the sequential search if the items were ordered in some way? Would we be able to gain any efficiency in our search technique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd7m-qCDJ14N",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume that the list of items was constructed so that the items are in ascending order, from low to high. If the item we are looking for is present in the list, the chance of it is still the same as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AngpG0KfJ14O",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If the item is not present there is a slight advantage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZd-K-Z-J14O",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/seqsearch2.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we are search for 50 no other elements beyond 54 can work. In this case, the algorithm does not have to continue looking through all of the items to report that the item was not found. It can stop immediately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def ordered_sequential_search(a_list, item):\n",
    "    pos = 0\n",
    "\n",
    "    while pos < len(a_list):\n",
    "        if a_list[pos] == item:\n",
    "            return True\n",
    "        if a_list[pos] > item:\n",
    "            return False\n",
    "        pos = pos + 1\n",
    "    return False\n",
    "\n",
    "test_list = [17, 20, 26, 31, 44, 54, 55, 65, 77, 93]\n",
    "print(ordered_sequential_search(test_list, 44))\n",
    "print(ordered_sequential_search(test_list, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The original complexity and the complexity of the ordered sequential search is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|         Case        | Best Case | Worst Case |  Average Case |\n",
    "|:-------------------:|:---------:|:----------:|:-------------:|\n",
    "|   item is present   |     1     |     $n$    | $\\frac{n}{2}$ |\n",
    "| item is not present |    $n$    |     $n$    |      $n$      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|         Case        | Best Case | Worst Case |  Average Case |\n",
    "|:-------------------:|:---------:|:----------:|:-------------:|\n",
    "|   item is present   |     1     |     $n$    | $\\frac{n}{2}$ |\n",
    "| item is not present |     1     |     $n$    | $\\frac{n}{2}$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, this technique is still $O(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb2mHWztJ14V",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.4 The Binary Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exxX2n_BJ14V",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is possible to take greater advantage of the ordered list if we are clever with our comparisons. A <u>binary search</u> will start by examining the middle item. If that item is the one we are searching for, we are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If it is not the correct item, we can use the ordered nature of the list to eliminate half of the remaining items!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXKHZgycJ14V",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If the item we are searching for is greater than the middle item, we know that the entire first (left) half of the list as well as the middle item can be eliminated from further consideration. The item, if it is in the list, must be in the second (right) half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtcIVAvjJ14V",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can then repeat the process with the left half. Start at the middle item and compare it against what we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb-FzjxHJ14W",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/binsearch.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUdT0USRJ14W",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The figure above shows how this algorithm can quickly find the value 54."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def binary_search(a_list, item):\n",
    "    first = 0\n",
    "    last = len(a_list) - 1\n",
    "    while first <= last:\n",
    "        midpoint = (first + last) // 2\n",
    "        print(midpoint - first)\n",
    "        if a_list[midpoint] == item:\n",
    "            return True\n",
    "        elif item < a_list[midpoint]:\n",
    "            last = midpoint - 1\n",
    "        else:\n",
    "            first = midpoint + 1\n",
    "    return False\n",
    "test_list = [17, 20, 26, 31, 44, 54, 55, 65, 77, 93]\n",
    "print(binary_search(test_list, 44))\n",
    "print(binary_search(test_list, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1683101092815,
     "user": {
      "displayName": "phonchi chung",
      "userId": "13517391734500420886"
     },
     "user_tz": -480
    },
    "id": "zFaZR6kPJ14a",
    "outputId": "4eee32f7-dc06-4c6e-d913-0204e4edce82",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This algorithm is a great example of a <u>divide and conquer</u> strategy. This means that we divide the problem into smaller pieces, solve the smaller pieces in some way, and then reassemble the whole problem to get the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDvyWSaCJ14b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is a **recursive call** to the binary search function passing a smaller list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def binary_search_rec(a_list, item):\n",
    "    if len(a_list) == 0:\n",
    "        return False\n",
    "    midpoint = (len(a_list) -1 )// 2 # Note this is different from textbook!\n",
    "    print(midpoint)\n",
    "    if a_list[midpoint] == item:\n",
    "        return True\n",
    "    elif item < a_list[midpoint]:\n",
    "        return binary_search_rec(a_list[:midpoint], item)\n",
    "    else:\n",
    "        return binary_search_rec(a_list[midpoint + 1 :], item)\n",
    "\n",
    "test_list = [17, 20, 26, 31, 44, 54, 55, 65, 77, 93]\n",
    "print(binary_search_rec(test_list, 44))\n",
    "print(binary_search_rec(test_list, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.4.1. Analysis of Binary Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is the maximum number of comparisons this algorithm will require to check the entire list? If we start with $n$ items, about $\\frac{n}{2}$ items will be left after the first comparison. After the second comparison, there will be about $\\frac{n}{4}$. Then $\\frac{n}{8}$, and so on. How many times can we split the list?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Comparisons | Approximate Number of Items Left |\n",
    "|:-----------:|:--------------------------------:|\n",
    "|      1      |           $\\frac{n}{2}$          |\n",
    "|      2      |           $\\frac{n}{4}$          |\n",
    "|      3      |           $\\frac{n}{8}$          |\n",
    "|     ...     |                                  |\n",
    "|     $i$     |          $\\frac{n}{2^i}$         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we split the list enough times, we end up with a list that has just one item. Either that is the item we are looking for or it is not. The number of comparisons necessary to get to this point is $i$ where $\\frac{n}{2^i}=1$. \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Solving for $i$ gives us $i = \\log n$. The maximum number of comparisons is logarithmic with respect to the number of items in the list. Therefore, the binary search is $O(\\log n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that the recursive call `binary_search_rec(a_list[:midpoint], item)` uses slicing operator to create the left half of the list that is then passed to the next invocation. However, we know that in `Python` it is actually $O(k)$. This means that the binary search using slicing will not perform in strict logarithmic time. Luckily this can be remedied by passing the list along with the starting and ending indices. We leave this implementation as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Even though a binary search is generally better than a sequential search, it is important to note that for small values of $n$, **the additional cost of sorting is probably not worth it**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we can sort once and then search many times, the cost of the sort is not so significant. However, for large lists, sorting even once can be so expensive that simply performing a sequential search from the start may be the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exercise 1: Implement the binary search using recursion without the slice operator. Recall that you will need to pass the list along with the starting and ending index values for the sublist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def binary_search_rec2(a_list, item, start, last):\n",
    "    if len(a_list) == 0:\n",
    "        return False\n",
    "    midpoint = (len(a_list) -1)// 2\n",
    "    print(midpoint)\n",
    "    if a_list[midpoint] == item:\n",
    "        return True\n",
    "    elif item < a_list[midpoint]:\n",
    "        return binary_search_rec2(a_list[:midpoint], item)\n",
    "    else:\n",
    "        return binary_search_rec2(a_list[midpoint + 1 :], item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_list = [17, 20, 26, 31, 44, 54, 55, 65, 77, 93]\n",
    "print(binary_search_rec2(test_list, 44,  0, len(test_list) - 1))\n",
    "print(binary_search_rec2(test_list, 50,  0, len(test_list) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6H4VdkAJ14c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.5 Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAszrEnnJ14d",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In previous sections we were able to make improvements in our search algorithms by taking advantage of information about where items are stored in the collection with respect to one another. For example, by knowing that a list was ordered, we could search in logarithmic time using a binary search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5cVK04hJ14d",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this section we will attempt to go one step further by building a data structure that can be searched in $O(1)$ time. This concept is referred to as <u>hashing</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzmywYm1J14e",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A <u>hash table</u> is a collection of items which are stored in such a way as to make it easy to find them later. Each position of the hash table, often called a **slot**, can hold an item and is named by an integer value starting at 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683102465996,
     "user": {
      "displayName": "phonchi chung",
      "userId": "13517391734500420886"
     },
     "user_tz": -480
    },
    "id": "1FJPykoruLi6",
    "outputId": "0129b8fa-a822-4b51-bfc3-7a4441616252",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, we will have a slot named 0, a slot named 1, a slot named 2, and so on. Initially, the hash table contains no items so every slot is empty. We can implement a hash table by using a list with each element initialized to `None`. Assume the size of the table is $m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhJfQMXwuZUA",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/hashtable.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The mapping between an item and the slot where that item belongs in the hash table is called the <u>hash function</u>. The hash function will take any item in the collection and return an integer in the range of slot names between 0 and $m-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume that we have the set of integer items 54, 26, 93, 17, 77, and 31. Our first hash function, sometimes referred to as the **remainder method**, simply takes an item and divides it by the table size, returning the remainder as its hash value $h(item)=item \\% 11$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Item | Hash value |\n",
    "|:----:|:----------:|\n",
    "|  54  |     10     |\n",
    "|  26  |      4     |\n",
    "|  93  |      5     |\n",
    "|  17  |      6     |\n",
    "|  77  |      0     |\n",
    "|  31  |      9     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once the hash values have been computed, we can insert each item into the hash table at the designated position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that 6 of the 11 slots are now occupied. This is referred to as the <u>load factor</u>, and is commonly denoted by $\\lambda= \\frac{number\\ of\\ items}{table\\ size}=\\frac{6}{11}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/hashtable2.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now when we want to search for an item, we simply use the hash function to compute the slot name for the item and then check the hash table to see if it is present. This searching operation is $O(1)$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can probably already see that this technique is going to work only if each item maps to a unique location in the hash table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, if the item 44 had been the next item in our collection, it would have a hash value of 0 ($44 \\% 11 = 0$). Since 77 also had a hash value of 0, we would have a problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "According to the hash function, two or more items would need to be in the same slot. This is referred to as a <u>collision</u> (it may also be called a clash). Clearly, collisions create a problem for the hashing technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.5.1. Hash Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a collection of items, a hash function that maps each item into a unique slot is referred to as a <u>perfect hash function</u>. Unfortunately, given an arbitrary collection of items, there is no systematic way to construct a perfect hash function. Luckily, we do not need the hash function to be perfect to still gain performance efficiency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our goal is to create a hash function that minimizes the number of collisions, is easy to compute, and evenly distributes the items in the hash table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that this remainder method (modulo) will typically be present in some form in all hash functions since the result must be in the range of slot names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The <u>folding method</u> for constructing hash functions begins by dividing the item into equal-sized pieces (the last piece may not be of equal size). These pieces are then added together to give the resulting hash value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, if our item was the phone number `436-555-4601`, we would take the digits and divide them into groups of 2 (43, 65, 55, 46, 01). After the addition, $43+65+55+46+01$, we get $210$. If we assume our hash table has 11 slots, then we need to perform the extra step of dividing by 11 and keeping the remainder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case $210 \\% 11$ is 1, so the phone number `436-555-4601` hashes to slot 1. Some folding methods go one step further and reverse every other piece before the addition. For the above example, we get $34+56+55+64+10=219$ which gives $219 \\%11 =10$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another numerical technique for constructing a hash function is called the <u>mid-square method</u>. We first square the item, and then extract some portion of the resulting digits. For example, if the item were 44, we would first compute $44^2=1936$. By extracting the middle two digits, 93, and performing the remainder step, we get 5 $(93\\%11)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Item | Remainder | Mid-Square |\n",
    "|:----:|:---------:|:----------:|\n",
    "|  54  |     10    |      3     |\n",
    "|  26  |     4     |      1     |\n",
    "|  93  |     5     |      9     |\n",
    "|  17  |     6     |      8     |\n",
    "|  77  |     0     |      4     |\n",
    "|  31  |     9     |      6     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def hash_functions(items, divisor):   \n",
    "    def remainder_method(item, divisor):\n",
    "        return item % divisor  \n",
    "    def midsquare_method(item, divisor):\n",
    "        squared = str(item ** 2)\n",
    "        # Ensure the squared string has even length for properly extracting middle digits\n",
    "        if len(squared) % 2 != 0:\n",
    "            squared = \"0\" + squared\n",
    "        middle = len(squared) // 2\n",
    "        mid_digits = int(squared[max(0, middle - 1):middle + 1])\n",
    "        return mid_digits % divisor\n",
    "    hash_table = [] * divisor\n",
    "    for item in items:\n",
    "        hash_entry = {\n",
    "            \"Item\": item, \"Remainder\": remainder_method(item, divisor),\n",
    "            \"Mid-Square\": midsquare_method(item, divisor)}\n",
    "        hash_table.append(hash_entry)\n",
    "    return hash_table\n",
    "\n",
    "items = [54, 26, 93, 17, 77, 31]\n",
    "remainder_divisor = 11 \n",
    "hash_results = hash_functions(items, remainder_divisor)\n",
    "hash_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also create hash functions for character-based items such as strings. For example, the word \"cat\" can be thought of as a sequence of ordinal values. We can then take these three ordinal values, add them up, and use the remainder method to get a hash value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/stringhash.png\" width=\"30%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def hash_str(a_string, table_size):\n",
    "    return sum([ord(c) for c in a_string]) % table_size\n",
    "\n",
    "print(hash_str(\"cat\", 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is interesting to note that when using this hash function, anagrams will always be given the same hash value. To remedy this, we could use the position of the character as a weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/stringhash2.png\" width=\"30%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The important thing to remember is that **the hash function has to be efficient** so that it does not become the dominant part of the storage and search process. Otherwise, we could just use the search as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.5.2. Collision Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now return to the problem of collisions. When two items hash to the same slot, we must have a systematic method for placing the second item in the hash table. This process is called <u>collision resolution</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A simple way to do this is to start at the original hash value position and then move in a sequential manner through the slots until we encounter the first slot that is empty. Note that we may need to go back to the first slot (circularly) to cover the entire hash table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This collision resolution process is referred to as <u>open addressing</u> in that it tries to find the next open slot or address in the hash table. By systematically visiting each slot one at a time, we are performing an open addressing technique called <u>linear probing</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider an extended set of integer items under the simple remainder method hash function (54, 26, 93, 17, 77, 31, 44, 55, 20). The following is the placement of the original first six values:\n",
    "\n",
    "<center><img src=\"imgs/hashtable2.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let’s see what happens when we attempt to place the additional three items into the table. When we attempt to place 44 into slot 0, a collision occurs. Under linear probing, we look sequentially, slot by slot, until we find an open position. In this case, we find slot 1. We can also do the same thing for the other values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/linearprobing1.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once we have built a hash table using open addressing and linear probing, it is essential that we utilize the same methods to search for items. If we are looking for 20 the hash value is 9, and slot 9 is currently holding 31. We cannot simply return `False` since we know that there could have been collisions. We are now forced to do a sequential search, starting at position 10, looking until either we find the item 20 or we find an empty slot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A disadvantage to linear probing is the tendency for **clustering**; This means that if many collisions occur at the same hash value, a number of surrounding slots will be filled by the linear probing resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This will have an impact on other items that are being inserted, as we saw when we tried to add the item 20 above. A cluster of values hashing to 0 had to be skipped to finally find an open position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/clustering.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One way to deal with clustering is to extend the linear probing technique so that instead of looking sequentially for the next open slot, we **skip slots**, thereby more evenly distributing the items that have caused collisions. The following shows the items when collision resolution is done with what we will call a \"plus 3\" probe. This means that once a collision occurs, we will look at every third slot until we find one that is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/linearprobing2.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The general name for this process of looking for another slot after a collision is <u>rehashing</u>. With simple linear probing, the rehash function is $new\\_hash=rehash(old\\_hash), rehash(pos)=(pos+skip)\\%size$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is important to note that the size of the skip must be such that all the slots in the table will eventually be visited. Otherwise, part of the table will be unused. To ensure this, it is often suggested that the **table size be a prime number**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def hash_functions_with_linear_probing(items, divisor):    \n",
    "    def remainder_method(item, divisor):\n",
    "        return item % divisor\n",
    "    hash_table = [None] * divisor\n",
    "    for item in items:\n",
    "        hash_index = remainder_method(item, divisor)        \n",
    "        # Linear probing in case of collision\n",
    "        while hash_table[hash_index] is not None:\n",
    "            hash_index = (hash_index + 1) % divisor\n",
    "        hash_table[hash_index] = item\n",
    "    hash_list = []\n",
    "    for idx, item in enumerate(hash_table):\n",
    "        if item is not None:  # Only include non-None items\n",
    "            hash_list.append({\"Item\": item, \"Hash Value\": idx})\n",
    "    return hash_list\n",
    "\n",
    "items = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "remainder_divisor = 11 \n",
    "hash_results = hash_functions_with_linear_probing(items, remainder_divisor)\n",
    "hash_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A variation of the linear probing idea is called <u>quadratic probing</u>. Instead of using a constant skip value, we use a rehash function that increments the hash value by 1, 4, 9 and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This means that if the first hash value is $h$, the successive values are $h+1, h+4, h+9$, and so on. In other words, quadratic probing uses a skip consisting of successive perfect squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/quadratic.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An alternative method for handling the collision problem is to allow each slot to hold a reference to a collection (or chain) of items. <u>Chaining</u> allows many items to exist at the same location in the hash table. When collisions happen, the item is still placed in the proper slot of the hash table. As more and more items hash to the same location, the difficulty of searching for the item in the collection increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/chaining.png\" width=\"35%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we want to search for an item, we use the hash function to generate the slot where it should reside. Since with chaining each slot holds a collection, we use a searching technique to decide whether the item is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exercise 2: Implement quadratic probing as a rehash technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def hash_functions_with_quadratic_probing(items, divisor):    \n",
    "    def remainder_method(item, divisor):\n",
    "        return item % divisor\n",
    "    hash_table = [None] * divisor\n",
    "    for item in items:\n",
    "        hash_index = remainder_method(item, divisor)        \n",
    "        # Linear probing in case of collision\n",
    "        while hash_table[hash_index] is not None:\n",
    "            hash_index = (hash_index + 1) % divisor\n",
    "        hash_table[hash_index] = item\n",
    "    hash_list = []\n",
    "    for idx, item in enumerate(hash_table):\n",
    "        if item is not None:  # Only include non-None items\n",
    "            hash_list.append({\"Item\": item, \"Hash Value\": idx})\n",
    "    return hash_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "items = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "remainder_divisor = 11\n",
    "hash_results = hash_functions_with_quadratic_probing(items, remainder_divisor)\n",
    "hash_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.5.3. Implementing the Map Abstract Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One of the most useful `Python` collections is the dictionary. Recall that a dictionary is a data type where you can store key-data pairs. The key is used to look up the associated data value. We often refer to this idea as a <u>map</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The map abstract data type is defined as follows. The structure is an unordered collection of associations between a key and a data value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `Map()` creates a new empty map.\n",
    "\n",
    "- `put(key, val)` adds a new key–value pair to the map. If the key is already in the map, it replaces the old value with the new value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `get(key)` takes a key and returns the matching value stored in the map or `None` otherwise.\n",
    "\n",
    "- `del` deletes the key–value pair from the map using a statement of the form `del map[key]`.\n",
    "\n",
    "- `size()` returns the number of key–value pairs stored in the map.\n",
    "\n",
    "- `in` return `True` for a statement of the form key in map if the given key is in the map, `False` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One of the great benefits of a dictionary is the fact that given a key, we can look up the associated data value very quickly. This could be done if we use a hash table as described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We use two lists to create a `HashTable` class that implements the map abstract data type. One list, called `slots`, will hold the key items and a parallel list, called `data`, will hold the data values. When we look up a key, the corresponding position in the data list will hold the associated data value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.slots = [None] * self.size\n",
    "        self.data = [None] * self.size\n",
    "        \n",
    "    def hash_function(self, key, size):\n",
    "        return key % size\n",
    "\n",
    "    def rehash(self, old_hash, size):\n",
    "        return (old_hash + 1) % size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def put(self, key, data):\n",
    "    hash_value = self.hash_function(key, len(self.slots))\n",
    "\n",
    "    if self.slots[hash_value] is None:\n",
    "        self.slots[hash_value] = key\n",
    "        self.data[hash_value] = data\n",
    "    else:\n",
    "        if self.slots[hash_value] == key:\n",
    "            self.data[hash_value] = data  # replace\n",
    "        else:\n",
    "            next_slot = self.rehash(hash_value, len(self.slots))\n",
    "            while (\n",
    "                self.slots[next_slot] is not None\n",
    "                and self.slots[next_slot] != key\n",
    "            ):\n",
    "                next_slot = self.rehash(next_slot, len(self.slots))\n",
    "\n",
    "            if self.slots[next_slot] is None:\n",
    "                self.slots[next_slot] = key\n",
    "                self.data[next_slot] = data\n",
    "            else:\n",
    "                self.data[next_slot] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`hash_function()` implements the simple remainder method. The collision resolution technique is linear probing with a \"plus 1\" rehash value. The `put()` function assumes that there will eventually be an empty slot. **If a nonempty slot already contains the key, the old data value is replaced with the new data value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get(self, key):\n",
    "    start_slot = self.hash_function(key, len(self.slots))\n",
    "\n",
    "    position = start_slot\n",
    "    while self.slots[position] is not None:\n",
    "        if self.slots[position] == key:\n",
    "            return self.data[position]\n",
    "        else:\n",
    "            position = self.rehash(position, len(self.slots))\n",
    "            if position == start_slot:\n",
    "                return None\n",
    "\n",
    "def __getitem__(self, key):\n",
    "    return self.get(key)\n",
    "\n",
    "def __setitem__(self, key, data):\n",
    "    self.put(key, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `get()` function begins by computing the initial hash value. If the value is not in the initial slot, rehash is used to locate the next possible position. Notice that line 10 guarantees that the search will terminate by checking to make sure that we have not returned to the initial slot. If that happens, we have exhausted all possible slots and the item must not be present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following session shows the `HashTable` class in action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./pythonds3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pythonds3.searching import HashTable\n",
    "\n",
    "h = HashTable(size=11)\n",
    "h[54], h[26] = \"cat\",  \"dog\"\n",
    "h[93], h[17] = \"lion\", \"tiger\"\n",
    "h[77], h[31] = \"bird\", \"cow\"\n",
    "h[44], h[55] = \"goat\", \"pig\"\n",
    "h[20] = \"chicken\"\n",
    "print(h._slots)\n",
    "print(h._data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next we will access and modify some items in the hash table. Note that the value for the key 20 is being replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(h[20])\n",
    "print(h[17])\n",
    "h[20] = \"duck\"\n",
    "print(h[20])\n",
    "print(h._data)\n",
    "print(h[99]) # Not in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.5.4. Analysis of Hashing (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We stated earlier that in the best case hashing would provide an $O(1)$, constant time search technique. However, due to collisions, the number of comparisons is typically not so simple. A complete analysis of hashing is beyond the scope of this text, we state some well-known results that approximate the number of comparisons necessary to search for an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The most important piece of information we need to analyze the use of a hash table is the load factor $\\lambda$. Conceptually, if $\\lambda$ is small, then there is a lower chance of collisions, meaning that items are more likely to be in the slots where they belong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $\\lambda$ is large, meaning that the table is filling up, then there are more and more collisions. This means that collision resolution is more difficult, requiring more comparisons to find an empty slot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As before, we will have a result for both a successful and an unsuccessful search. For a successful search using open addressing with linear probing, the average number of comparisons is approximately $\\frac{1}{2}\\left(1+\\frac{1}{1-\\lambda}\\right)$ and an unsuccessful search gives $\\frac{1}{2}\\left(1+\\left(\\frac{1}{1-\\lambda}\\right)^2\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we are using chaining, the average number of comparisons is $1 + \\frac {\\lambda}{2}$ for the successful case, and simply \n",
    " $\\lambda$ comparisons if the search is unsuccessful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.6 Sorting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<u>Sorting</u> is the process of placing elements from a collection in some kind of order. For example, a list of words could be sorted alphabetically or by length. We have already seen a number of algorithms that were able to benefit from having a sorted list (recall the final anagram example and the binary search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sorting a large number of items can take a substantial amount of computing resources. Like searching, the efficiency of a sorting algorithm is related to the number of items being processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For small collections, a complex sorting method may be more trouble than it is worth. The overhead may be too high. On the other hand, for larger collections, we want to take advantage of as many improvements as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this section we will discuss several sorting techniques and compare them with respect to their running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We should think about the operations that can be used to analyze a sorting process. First, it will be necessary to compare two values to see which is smaller (or larger). In order to sort a collection, it will be necessary to have some systematic way to compare values to see if they are out of order. The **total number of comparisons** will be the most common way to measure a sort procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Second, when values are not in the correct position with respect to one another, it may be necessary to exchange them. This exchange is a costly operation and the **total number of exchanges** will also be important for evaluating the overall efficiency of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.7. The Bubble Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The <u>bubble sort</u> makes multiple passes through a list. It compares adjacent items and exchanges those that are out of order. Each pass through the list places the next largest value in its proper place. In essence, each item bubbles up to the location where it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/bubblepass.png\" width=\"35%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If there are $n$ items in the list, then there are $n-1$ pairs of items that need to be compared on the first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At the start of the second pass, the largest value is now in place. There are $n-1$ items left to sort, meaning that there will be $n-2$ pairs. Since each pass places the next largest value in place, the total number of passes necessary will be $n-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The exchange operation, sometimes called a **swap**, is slightly different in `Python` than in most other programming languages. Typically, swapping two elements in a list requires a temporary variable (an additional memory location). \n",
    "\n",
    "```\n",
    "temp = a_list[i]\n",
    "a_list[i] = a_list[j]\n",
    "a_list[j] = temp\n",
    "```\n",
    "\n",
    "Without the temporary storage, one of the values would be overwritten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In `Python`, it is possible to perform simultaneous assignment. The statement `a, b = b, a` will result in two assignment statements being done at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<center><img src=\"imgs/swap.png\" width=\"30%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def bubble_sort(a_list):\n",
    "    for i in range(len(a_list) - 1, 0, -1):\n",
    "        for j in range(i):\n",
    "            if a_list[j] > a_list[j + 1]:\n",
    "                temp = a_list[j]\n",
    "                a_list[j] = a_list[j + 1]\n",
    "                a_list[j + 1] = temp\n",
    "\n",
    "\n",
    "a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "bubble_sort(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "iframe = f'<iframe src=\"https://opendsa-server.cs.vt.edu/embed/bubblesortAV\" height=\"650\" width=\"100%\" scrolling=\"no\"></iframe> '\n",
    "display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://visualgo.net/en/sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To analyze the bubble sort, we should note that regardless of how the items are arranged in the initial list, $n-1$ passes will be made to sort a list of size $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|  Pass | Comparisons |\n",
    "|:-----:|:-----------:|\n",
    "|   1   |    n-1    |\n",
    "|   2   |    n-2    |\n",
    "|   3   |    n-3    |\n",
    "|  `...`  |     `...`     |\n",
    "| n-1 |     1     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The total number of comparisons is the sum of the first $n$ integers which is $\\frac{1}{2}n^{2} - \\frac{1}{2}n$. This is $O(n^2)$ comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A bubble sort is often considered the most inefficient sorting method since it must exchange items before the final location is known. These \"wasted\" exchange operations are very costly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, because the bubble sort makes passes through the entire unsorted portion of the list, it has the capability to do something most sorting algorithms cannot. In particular, if during a pass there are no exchanges, then we know that the list must be sorted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def bubble_sort_short(a_list):\n",
    "    for i in range(len(a_list) - 1, 0, -1):\n",
    "        exchanges = False\n",
    "        for j in range(i):\n",
    "            if a_list[j] > a_list[j + 1]:\n",
    "                exchanges = True\n",
    "                a_list[j], a_list[j + 1] = a_list[j + 1], a_list[j]\n",
    "        if not exchanges:\n",
    "            break\n",
    "\n",
    "\n",
    "a_list = [20, 30, 40, 90, 50, 60, 70, 80, 100, 110]\n",
    "bubble_sort_short(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is often called **short bubble**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.8. The Selection Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The <u>selection sort</u> improves on the bubble sort by making **only one exchange for every pass** through the list. Selection sort looks for the largest value as it makes a pass and, after completing the pass, places it in the proper location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As with a bubble sort, after the first pass, the largest item is in the correct place. After the second pass, the next largest is in place. This process continues and requires $n-1$ passes to sort $n$ items, since the final item must be in place after the $n-1$ pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"imgs/selectionsortnew.png\" width=\"36%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def selection_sort(a_list):\n",
    "    for i, item in enumerate(a_list):\n",
    "        min_idx = i\n",
    "        for j in range(i, len(a_list)):\n",
    "            if a_list[j] < a_list[min_idx]:\n",
    "                min_idx = j\n",
    "        if min_idx != i:\n",
    "            a_list[min_idx], a_list[i] = a_list[i], a_list[min_idx]\n",
    "\n",
    "a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "selection_sort(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "iframe = f'<iframe src=\"https://opendsa-server.cs.vt.edu/embed/selectionsortAV\" height=\"650\" width=\"100%\" scrolling=\"no\"></iframe> '\n",
    "display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You may see that the selection sort makes the same number of comparisons as the bubble sort and is therefore also $O(n^2)$. However, due to the reduction in the number of exchanges, the selection sort typically executes faster in benchmark studies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.9 The Insertion Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The <u>insertion sort</u>, although still $O(n^2)$, works in a slightly different way. It always maintains a **sorted sublist in the lower positions of the list**. Each new item is then inserted back into the previous sublist such that the sorted sublist is one item larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/insertionsort.png\" width=\"36%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We begin by assuming that a list with one item (position $0$) is already sorted. On each pass, one for each item 1 through \n",
    "$n-1$, the current item is checked against those in the already sorted sublist. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As we look back into the already sorted sublist, we shift those items that are greater to the right. When we reach a smaller item or the end of the sublist, the current item can be inserted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/insertionpass.png\" width=\"36%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The implementation of `insertion_sort()` shows that there are again $n-1$ passes to sort $n$ items. The iteration starts at position 1 and moves through position $n-1$, as these are the items that need to be inserted back into the sorted sublists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def insertion_sort(a_list):\n",
    "    for i in range(1, len(a_list)):\n",
    "        cur_val = a_list[i]\n",
    "        cur_pos = i\n",
    "\n",
    "        while cur_pos > 0 and a_list[cur_pos - 1] > cur_val:\n",
    "            a_list[cur_pos] = a_list[cur_pos - 1]\n",
    "            cur_pos = cur_pos - 1\n",
    "        a_list[cur_pos] = cur_val\n",
    "\n",
    "a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "insertion_sort(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "iframe = f'<iframe src=\"https://opendsa-server.cs.vt.edu/embed/insertionsortAV\" height=\"650\" width=\"100%\" scrolling=\"no\"></iframe> '\n",
    "display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Line 7 performs the shift operation that moves a value up one position in the list, making room behind it for the insertion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The maximum number of comparisons for an insertion sort is the sum of the first $n-1$ integers. Again, this is $O(n^2)$. However, in the best case, only one comparison needs to be done on each pass. This would be the case for an already sorted list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One note about shifting versus exchanging is also important. **In general, a shift operation requires approximately a third of the processing work of an exchange since only one assignment is performed.** In benchmark studies, insertion sort will show very good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.10. The Shell Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The <u>Shell sort</u>, sometimes called the **diminishing increment sort**, improves on the insertion sort by breaking the original list into a number of smaller sublists, each of which is sorted using an insertion sort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead of breaking the list into sublists of contiguous items, the Shell sort uses an increment $i$, sometimes called the **gap**, to create a sublist by choosing all items that are $i$ items apart. If we use an increment of three, there are three sublists, each of which can be sorted by an insertion sort. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/shellsortA.png\" width=\"36%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After completing these sorts, we get:\n",
    "\n",
    "<center><img src=\"imgs/shellsortB.png\" width=\"33%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By sorting the sublists, we have moved the items closer to where they actually belong. The final insertion sort using an increment of one—in other words, a standard insertion sort. Note that by performing the earlier sublist sorts, we have now reduced the total number of shifting operations necessary to put the list in its final order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For this case, we need only four more shifts to complete the process.\n",
    "\n",
    "<center><img src=\"imgs/shellsortC.png\" width=\"33%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The way in which the increments are chosen is the unique feature of the Shell sort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def shell_sort(a_list):\n",
    "    sublist_count = len(a_list) // 2\n",
    "    while sublist_count > 0:\n",
    "        for pos_start in range(sublist_count):\n",
    "            gap_insertion_sort(a_list, pos_start, sublist_count)\n",
    "        print(\"After increments of size\", sublist_count, \"the list is\", a_list)\n",
    "        sublist_count = sublist_count // 2\n",
    "\n",
    "\n",
    "def gap_insertion_sort(a_list, start, gap):\n",
    "    for i in range(start + gap, len(a_list), gap):\n",
    "        cur_val = a_list[i]\n",
    "        cur_pos = i\n",
    "        while cur_pos >= gap and a_list[cur_pos - gap] > cur_val:\n",
    "            a_list[cur_pos] = a_list[cur_pos - gap]\n",
    "            cur_pos = cur_pos - gap\n",
    "        a_list[cur_pos] = cur_val\n",
    "\n",
    "\n",
    "a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "shell_sort(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"imgs/shellsortD.png\" width=\"33%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "iframe = f'<iframe src=\"https://opendsa-server.cs.vt.edu/embed/shellsortAV\" height=\"650\" width=\"100%\" scrolling=\"no\"></iframe> '\n",
    "display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, we begin with $\\frac{n}{2}$ sublists. On the next pass, $\\frac{n}{4}$ sublists are sorted. Eventually, a single list is sorted with the basic insertion sort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "At first glance you may think that a Shell sort cannot be better than an insertion sort since it does a complete insertion sort as the last step. It turns out, however, that this final insertion sort does not need to do very many comparisons (or shifts) since the list has been presorted by earlier incremental insertion sorts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Although a general analysis of the Shell sort is well beyond the scope of this text, we can say that it tends to fall somewhere between $O(n^2)$ and $O(n)$. By changing the increment, for example using $2^k-1$ (1, 3, 7, 15, 31, and so on), a Shell sort can perform at $O(n^{\\frac{3}{2}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.11 The Merge Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now turn our attention to using a divide and conquer strategy as a way to improve the performance of sorting algorithms. The first algorithm we will study is the <u>merge sort</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Merge sort is a recursive algorithm that continually splits a list in half. If the list is empty or has one item, it is sorted by definition (the base case). If the list has more than one item, we split the list and recursively invoke a merge sort on both halves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/mergesortA.png\" width=\"33%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once the two halves are sorted, the fundamental operation, called a **merge**, is performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Merging is the process of taking two smaller sorted lists and combining them together into a single sorted new list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/mergesortB.png\" width=\"33%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def merge_sort(a_list):\n",
    "    print(\"Splitting\", a_list)\n",
    "    if len(a_list) > 1:\n",
    "        mid = len(a_list) // 2\n",
    "        left_half, right_half = a_list[:mid], a_list[mid:]\n",
    "        \n",
    "        merge_sort(left_half)\n",
    "        merge_sort(right_half)\n",
    "        \n",
    "        # Initialize pointers for traversing the two halves\n",
    "        i, j, k = 0, 0, 0\n",
    "        # As long as there are elements in both halves, we perform merging\n",
    "        while i < len(left_half) and j < len(right_half):\n",
    "            # Compare the current elements of both halves and merge them in sorted order\n",
    "            if left_half[i] <= right_half[j]:\n",
    "                a_list[k] = left_half[i]\n",
    "                i = i + 1\n",
    "            else:\n",
    "                a_list[k] = right_half[j]\n",
    "                j = j + 1\n",
    "            k = k + 1\n",
    "        # If there are remaining elements in the left half, append them\n",
    "        while i < len(left_half):\n",
    "            a_list[k] = left_half[i]\n",
    "            i = i + 1\n",
    "            k = k + 1\n",
    "        # If there are remaining elements in the right half, append them\n",
    "        while j < len(right_half):\n",
    "            a_list[k] = right_half[j]\n",
    "            j = j + 1\n",
    "            k = k + 1\n",
    "    print(\"Merging\", a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "iframe = f'<iframe src=\"https://opendsa-server.cs.vt.edu/embed/mergesortAV\" height=\"650\" width=\"100%\" scrolling=\"no\"></iframe> '\n",
    "display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The code begins by asking the base case question. If the length of the list is less than or equal to one, then we already have a sorted list and no more processing is necessary. If, on the other hand, the length is greater than one, then we use the `Python` slice operation to extract the left and right halves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a_list = [54, 26, 93, 17, 77]\n",
    "merge_sort(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once the `merge_sort()` function is invoked on the left half and the right half (lines 7–8), it is assumed they are sorted. The rest of the function is responsible for merging the two smaller sorted lists into a larger sorted list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the merge operation places the items back into the original list (`a_list`) one at a time by repeatedly taking the smallest item from the sorted lists. The condition in line 15 (`left_half[i] <= right_half[j]`) ensures that the algorithm is stable. A <u>stable algorithm</u> maintains the order of duplicate items in a list and is preferred in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to analyze the merge_sort function, we need to consider the two distinct processes that make up its mplementation. First, the list is split into halves. We already computed (in a binary search) that we can divide a list in half $\\log n$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The second process is the merge. Each item in the list will eventually be processed and placed on the sorted list. So the merge operation requires $n$ operations **in each level**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The result of this analysis is that $\\log n$ splits, each of which costs $n$ for a total of $n\\log n$ operations. A merge sort is an $O(n\\log n)$ algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Recall that the slicing operator is $O(k)$ where $k$ is the size of the slice. We will need to remove the slice operator. Again, this is possible if we simply pass the starting and ending indices along with the list when we make the recursive call. We leave this as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is important to notice that the `merge_sort()` function requires extra space to hold the two halves as they are extracted with the slicing operations. This additional space can be a critical factor if the list is large and can make this sort problematic when working on large data sets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.12. The Quicksort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The <u>quicksort</u> uses divide and conquer to gain the same advantages as the merge sort, while not using additional storage. As a trade-off, however, it is possible that the list may not be divided in half. When this happens, we will see that performance is diminished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A quicksort first selects a <u>pivot value</u>. Although there are many different ways to choose the pivot value, we will simply use the first item in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The role of the pivot value is to assist with splitting the list. The actual position where the pivot value belongs in the final sorted list, commonly called the **split point**, will be used to divide the list for subsequent calls to the quicksort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In below, 54 will serve as our first pivot value\n",
    "\n",
    "<center><img src=\"imgs/firstsplit.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The **partition process** will happen next. It will find the split point and at the same time move other items to the appropriate side of the list, either less than or greater than the pivot value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Partitioning begins by locating two position markers — let's call them `left_mark` and `right_mark` — at the beginning and end of the remaining items in the list. The goal of the partition process is to move items that are on the wrong side with respect to the pivot value while also converging on the split point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"imgs/partitionA.png\" width=\"35%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We begin by incrementing `left_mark` until we locate a value that is greater than the pivot value. We then decrement `right_mark` until we find a value that is less than the pivot value. At this point we have discovered two items that are out of place with respect to the eventual split point. Now we can exchange these two items and then repeat the process again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At the point where `right_mark` becomes less than `left_mark`, we stop. The position of `right_mark` is now the split point! The pivot value can be exchanged with the contents of the split point and the pivot value is now in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In addition, all the items to the left of the split point are less than the pivot value, and all the items to the right of the split point are greater than the pivot value. The list can now be divided at the split point and the quicksort can be invoked recursively on the two halves!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"imgs/partitionB.png\" width=\"40%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def quick_sort(a_list):\n",
    "    quick_sort_helper(a_list, 0, len(a_list) - 1)\n",
    "\n",
    "\n",
    "def quick_sort_helper(a_list, first, last):\n",
    "    if first < last:\n",
    "        split = partition(a_list, first, last)\n",
    "        quick_sort_helper(a_list, first, split - 1)\n",
    "        quick_sort_helper(a_list, split + 1, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def partition(a_list, first, last):\n",
    "    pivot_val = a_list[first]\n",
    "    left_mark = first + 1\n",
    "    right_mark = last\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        while left_mark <= right_mark and a_list[left_mark] <= pivot_val:\n",
    "            left_mark = left_mark + 1\n",
    "        while left_mark <= right_mark and a_list[right_mark] >= pivot_val:\n",
    "            right_mark = right_mark - 1\n",
    "        if right_mark < left_mark:\n",
    "            done = True\n",
    "        else:\n",
    "            a_list[left_mark], a_list[right_mark] = (\n",
    "                a_list[right_mark],\n",
    "                a_list[left_mark],\n",
    "            )\n",
    "    a_list[first], a_list[right_mark] = a_list[right_mark], a_list[first]\n",
    "\n",
    "    return right_mark\n",
    "\n",
    "a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "quick_sort(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "iframe = f'<iframe src=\"https://opendsa-server.cs.vt.edu/embed/quicksortAV\" height=\"650\" width=\"100%\" scrolling=\"no\"></iframe> '\n",
    "display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To analyze the quick_sort function, note that if the partition always occurs in the middle of the list, there will again be \n",
    "$O(\\log n)$ divisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to find the split point, each of the $n$ items needs to be checked against the pivot value. The result is $O(n \\log n)$. In addition, there is no need for additional memory as in the merge sort process!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unfortunately, in the worst case, the split points may not be in the middle and can be very skewed to the left or the right, leaving a very uneven division. In this case, it divides into sorting a list of 0 items and a list of $n-1$ items. Then sorting a list of $n-1$ divides into a list of size 0 and a list of size $n-2$, and so on. The result is an $O(n^2)$ sort with all of the overhead that recursion requires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We mentioned earlier that there are different ways to choose the pivot value. In particular, we can attempt to alleviate some of the potential for an uneven division by using a technique called <u>median of three</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To choose the pivot value, we will consider the first, the middle, and the last element in the list. In our example, those are 54, 77, and 20. Now pick the median value, in our case 54, and use it for the pivot value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The idea is that in the case where the first item in the list does not belong toward the middle of the list, the median of three will choose a better “middle” value. This will be particularly useful when the original list is somewhat sorted to begin with. We leave the implementation of this pivot value selection as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exercise 3: Implement quick sort so that it supports sorting in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def quick_sort(a_list, descending=False):\n",
    "    quick_sort_helper(a_list, 0, len(a_list) - 1, descending)\n",
    "\n",
    "def quick_sort_helper(a_list, first, last, descending):\n",
    "    if first < last:\n",
    "        split = partition(a_list, first, last, descending)\n",
    "        quick_sort_helper(a_list, first, split - 1, descending)\n",
    "        quick_sort_helper(a_list, split + 1, last, descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def partition(a_list, first, last, descending):\n",
    "    pivot_val = a_list[first]\n",
    "    left_mark = first + 1\n",
    "    right_mark = last\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        while left_mark <= right_mark and a_list[left_mark] <= pivot_val:\n",
    "            left_mark = left_mark + 1\n",
    "        while left_mark <= right_mark and a_list[right_mark] >= pivot_val:\n",
    "            right_mark = right_mark - 1\n",
    "        if right_mark < left_mark:\n",
    "            done = True\n",
    "        else:\n",
    "            a_list[left_mark], a_list[right_mark] = (\n",
    "                a_list[right_mark],\n",
    "                a_list[left_mark],\n",
    "            )\n",
    "    a_list[first], a_list[right_mark] = a_list[right_mark], a_list[first]\n",
    "\n",
    "    return right_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "a_list = [54, 26, 93, 17, 77, 31, 44, 55, 20]\n",
    "print(\"Original list:\", a_list)\n",
    "quick_sort(a_list, descending=False)\n",
    "print(\"Sorted in ascending order:\", a_list)\n",
    "quick_sort(a_list, descending=True)\n",
    "print(\"Sorted in descending order:\", a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2teyKp_e1khl",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Textbook CH5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Key terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "1. **Searching**: The act of locating a specific number or entry within a collection based on predefined criteria or characteristics.\n",
    "\n",
    "2. **Sorting**: The process by which numbers in a dataset are arranged in a specific sequence, typically ascending or descending order, based on their values.\n",
    "\n",
    "3. **Sequential Search**: A search technique where each number in a list is examined one by one from the start until the desired number is found or the list ends.\n",
    "\n",
    "4. **Binary Search**: A search algorithm applied on a sorted array that repeatedly divides the search range in half, comparing the midpoint against the target number to find it efficiently.\n",
    "\n",
    "5. **Divide and Conquer**: A strategy for solving problems by breaking them into smaller subproblems of the same type, solving these subproblems independently, and combining their solutions to solve the original problem.\n",
    "\n",
    "6. **Hashing**: A method used for uniquely identifying a specific number from a set of numbers by converting the input into a fixed-size string or number through a hash function.\n",
    "\n",
    "7. **Hash Table**: A data structure that implements an associative array abstract data type, allowing for the efficient retrieval of values keyed by numbers, through hashing.\n",
    "\n",
    "8. **Collision**: This occurs when two different keys (numbers) hash to the same index in a hash table.\n",
    "\n",
    "9. **Perfect Hash Function**: A hash function that, when applied to each key (number) in the input set, produces a unique index in the hash table, thus eliminating collisions.\n",
    "\n",
    "10. **Remainder Method**: A method for generating a hash value by taking the remainder of the division of the key (number) by the hash table size.\n",
    "\n",
    "11. **Folding Method**: A technique for hashing where a key (number) is divided into parts, these parts are then added together, and the hash value is derived from this sum.\n",
    "\n",
    "12. **Mid-square Method**: A hashing technique where the key (number) is squared, and a portion of the resulting number (often the middle part) is used as the hash value.\n",
    "\n",
    "13. **Collision Resolution**: Various strategies, such as chaining or open addressing, used to address the issue of two keys hashing to the same index in a hash table.\n",
    "\n",
    "14. **Open Addressing**: A method of resolving hash table collisions by probing the hash table to find the next empty slot according to a predefined sequence.\n",
    "\n",
    "15. **Linear Probing**: A specific type of open addressing where the next sequential slot is checked for availability after a collision.\n",
    "\n",
    "16. **Rehashing**: The process of increasing the size of a hash table and rehashing all existing keys (numbers), typically performed when the load factor exceeds a certain threshold.\n",
    "\n",
    "17. **Quadratic Probing**: A collision resolution technique in open addressing that uses a quadratic function to find the next slot, reducing clustering compared to linear probing.\n",
    "\n",
    "18. **Chaining**: A collision resolution technique in hash tables where each table index points to a list (or chain) of entries that hash to the same index. This allows multiple values to be stored at the same location by linking them together.\n",
    "\n",
    "19. **Map**: A data structure that stores pairs of keys and values, allowing for efficient retrieval of a value based on its associated key (number).\n",
    "\n",
    "20. **Loading Factor**: A measure of how full a hash table is, calculated as the ratio of the number of entries to the total number of slots available in the table.\n",
    "\n",
    "21. **Bubble Sort**: A straightforward sorting algorithm that repeatedly steps through the list to be sorted, compares adjacent numbers, and swaps them if they are in the wrong order.\n",
    "\n",
    "22. **Selection Sort**: An in-place comparison sorting algorithm that segments the list into two parts: sorted and unsorted. It repeatedly selects the minimum number from the unsorted segment and moves it to the end of the sorted segment.\n",
    "\n",
    "23. **Insertion Sort**: A simple sorting technique that builds the final sorted array (or list) one number at a time, inserting each new number into its proper position within the sorted portion.\n",
    "\n",
    "24. **Shell Sort**: An algorithm that sorts numbers by comparing elements separated by a gap of several positions, reducing the gap size over time until it reaches one.\n",
    "\n",
    "25. **Gap**: The term \"gap\" refers to the distance between numbers being compared and sorted in the context of the Shell Sort algorithm.\n",
    "\n",
    "26. **Merge Sort**: A divide-and-conquer sorting algorithm that divides the unsorted list into n sublists, each containing one number, then repeatedly merges sublists to produce new sorted sublists until there is only one sublist remaining.\n",
    "\n",
    "27. **Stable Sort**: A sorting algorithm is considered stable if it maintains the relative order of numbers with equal values within the sorted list.\n",
    "\n",
    "28. **Quick Sort**: An efficient sorting algorithm that employs a divide-and-conquer strategy to select a 'pivot' number and partition the array into two halves, such that numbers less than the pivot are on one side, and those greater are on the other.\n",
    "\n",
    "29. **Pivot Value**: The chosen value around which the quick sort algorithm organizes the other numbers in the array during the partitioning process.\n",
    "\n",
    "30. **Split Point**: The position at which the pivot number is placed in the sorted array, such that all numbers to the left are smaller and all numbers to the right are larger.\n",
    "\n",
    "31. **Partition Process**: The critical step in quick sort where numbers are rearranged so that those less than a chosen pivot number are moved to its left, and those greater to its right.\n",
    "\n",
    "32. **Median of Three**: A strategy to choose the pivot number in quick sort, typically by finding the median value of the first, middle, and last numbers of the portion of the array being sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "cDAMEH2XJ14T"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "chalkboard": {
    "color": [
     "rgb(250, 0, 0)",
     "rgb(250, 0, 0)"
    ]
   },
   "controls": false,
   "enable_chalkboard": true,
   "footer": "",
   "overlay": "<div class='myfooter'><h4>Searching and Sorting</h4></div>",
   "slideNumber": "true",
   "theme": "night"
  },
  "vscode": {
   "interpreter": {
    "hash": "1561eddc5e0c9c74df968f74d5080d02882967127f956e6e7049c43d2ef42321"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
