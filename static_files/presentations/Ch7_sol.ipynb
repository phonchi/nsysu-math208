{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"QvapVWPoW88y"},"source":["# Exercise 7"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z-rQC77mXHJ3"},"source":["### (1) What creates hash collisions?\n","\n","(A) when pairs of different hash values are mapped to the same key.\n","\n","(B) when pairs of different hash values do not share the same key.\n","\n","(C) when pairs of different keys are mapped to the same hash value.\n","\n","(D) when pairs of different keys do not share the same hash value."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["(C)"]},{"cell_type":"markdown","metadata":{},"source":["### (2) Suppose you are doing a sequential search of the list `[15, 18, 2, 19, 18, 0, 8, 14, 19, 14]`. How many comparisons would you need to do in order to find the key 18?\n","\n","(A) 5\n","\n","(B) 10\n","\n","(C) 4\n","\n","(D) 2"]},{"cell_type":"markdown","metadata":{},"source":["(D)"]},{"cell_type":"markdown","metadata":{},"source":["### (3) Suppose you have the following sorted list `[3, 5, 6, 8, 11, 12, 14, 15, 17, 18]` and are using the binary search algorithm. Which group of numbers correctly shows the sequence of comparisons used to find the key 8.\n","\n","(A) 11, 5, 6, 8\n","\n","(B) 12, 6, 11, 8\n","\n","(C) 3, 5, 6, 8\n","\n","(D) 18, 12, 6, 8"]},{"cell_type":"markdown","metadata":{},"source":["(A)"]},{"cell_type":"markdown","metadata":{},"source":["### (4) Suppose you have the following list of numbers to sort: `[19, 1, 9, 7, 3, 10, 13, 15, 8, 12]` which list represents the partially sorted list after three complete passes of bubble sort?"]},{"cell_type":"markdown","metadata":{},"source":["(A) `[1, 9, 19, 7, 3, 10, 13, 15, 8, 12]`\n","\n","(B) `[1, 3, 7, 9, 10, 8, 12, 13, 15, 19]`\n","\n","(C) `[1, 7, 3, 9, 10, 13, 8, 12, 15, 19]`\n","\n","(D) `[1, 9, 19, 7, 3, 10, 13, 15, 8, 12]`"]},{"cell_type":"markdown","metadata":{},"source":["(B)"]},{"cell_type":"markdown","metadata":{},"source":["### (5) Suppose you have the following list of numbers to sort: `[11, 7, 12, 14, 19, 1, 6, 18, 8, 20]` which list represents the partially sorted list after three complete passes of selection sort assumming that we swap the smallest element to the begining in each pass?\n","\n","(A) `[1, 6, 7, 14, 19, 11, 12, 18, 8, 20]`\n","\n","(B) `[7, 11, 12, 14, 19, 1, 6, 18, 8, 20]`\n","\n","(C) `[1, 6, 7, 14, 19, 1, 6, 18, 8, 20]`\n","\n","(D) `[11, 7, 12, 14, 8, 1, 6, 18, 19, 20]`"]},{"cell_type":"markdown","metadata":{},"source":["(A)"]},{"cell_type":"markdown","metadata":{},"source":["### (6) Suppose you have the following list of numbers to sort: `[15, 5, 4, 18, 12, 19, 14, 10, 8, 20]` which list represents the partially sorted list after three complete passes of insertion sort?\n","\n","(A) `[4, 5, 12, 15, 14, 10, 8, 18, 19, 20]`\n","\n","(B) `[15, 5, 4, 10, 12, 8, 14, 18, 19, 20]`\n","\n","(C) `[4, 5, 15, 18, 12, 19, 14, 10, 8, 20]`\n","\n","(D) `[15, 5, 4, 18, 12, 19, 14, 8, 10, 20]`"]},{"cell_type":"markdown","metadata":{},"source":["(C)"]},{"cell_type":"markdown","metadata":{},"source":["### (7) Given the following list of numbers: `[5, 16, 20, 12, 3, 8, 9, 17, 19, 7]` Which answer illustrates the contents of the list after all swapping is complete for a gap size of 3 in a shell sort?\n","\n","(A) `[5, 3, 8, 7, 16, 19, 9, 17, 20, 12]`\n","\n","(B) `[3, 7, 5, 8, 9, 12, 19, 16, 20, 17]`\n","\n","(C) `[3, 5, 7, 8, 9, 12, 16, 17, 19, 20]`\n","\n","(D) `[5, 16, 20, 3, 8, 12, 9, 17, 20, 7]`"]},{"cell_type":"markdown","metadata":{},"source":["(A)"]},{"cell_type":"markdown","metadata":{},"source":["### (8) Given the following list of numbers: `[21, 1, 26, 45, 29, 28, 2, 9, 16, 49, 39, 27, 43, 34, 46, 40]` which answer illustrates the first two lists to be merged?\n","\n","(A) `[21, 1]` and `[26, 45]`\n","\n","(B) `[1, 2, 9, 21, 26, 28, 29, 45]` and `[16, 27, 34, 39, 40, 43, 46, 49]`\n","\n","(C) `[21]` and `[1]`\n","\n","(D) `[9]` and `[16]`"]},{"cell_type":"markdown","metadata":{},"source":["(C)"]},{"cell_type":"markdown","metadata":{},"source":["### (9) Which of the following sort algorithms are guaranteed to be $O(n \\log n)$ even in the worst case?"]},{"cell_type":"markdown","metadata":{},"source":["(A) Shell Sort\n","\n","(B) Quick Sort\n","\n","(C) Merge Sort\n","\n","(D) Insertion Sort"]},{"cell_type":"markdown","metadata":{},"source":["(C)"]},{"cell_type":"markdown","metadata":{},"source":["### (10) Given the following list of numbers `[1, 20, 11, 5, 2, 9, 16, 14, 13, 19]` what would be the first pivot value using the median of 3 method in quick sort?\n","\n","(A) 1\n","\n","(B) 9\n","\n","(C) 16\n","\n","(D) 19"]},{"cell_type":"markdown","metadata":{},"source":["(B)"]},{"cell_type":"markdown","metadata":{},"source":["### (11) Suppose you are given the following set of keys to insert into a hash table that holds exactly 11 values: `113 , 117 , 97 , 100 , 114 , 108 , 116 , 105 , 99`. What is contents of the hash table after all the keys have been inserted using linear probing?"]},{"cell_type":"markdown","metadata":{},"source":["Ans: \n","\n","Here are the steps, calculating the hash for each key and placing it into the table, resolving collisions using linear probing:\n","\n","1. **Hash Table Setup**: The hash table has 11 slots, initially empty:\n","\n","   `[ -, -, -, -, -, -, -, -, -, -, - ]`\n"," \n","\n","2. **Inserting Each Key**:\n","   - **Key 113**: $113 \\mod 11 = 3$\n","\n","     `[ -, -, -, 113, -, -, -, -, -, -, - ]`\n","\n","   - **Key 117**: $117 \\mod 11 = 7$\n","     `[ -, -, -, 113, -, -, -, 117, -, -, - ]`\n","\n","   - **Key 97**: $97 \\mod 11 = 9$\n","\n","     `[ -, -, -, 113, -, -, -, 117, -, 97, - ]`\n","\n","   - **Key 100**: $100 \\mod 11 = 1$\n","\n","     `[ -, 100, -, 113, -, -, -, 117, -, 97, - ]`\n","\n","   - **Key 114**: $114 \\mod 11 = 4$\n","\n","     `[ -, 100, -, 113, 114, -, -, 117, -, 97, - ]`\n","\n","   - **Key 108**: $108 \\mod 11 = 9$, but slot 9 is occupied, so linear probe to slot 10.\n","\n","     `[ -, 100, -, 113, 114, -, -, 117, -, 97, 108 ]`\n","\n","   - **Key 116**: $116 \\mod 11 = 6$\n","\n","     `[ -, 100, -, 113, 114, -, 116, 117, -, 97, 108 ]`\n","\n","   - **Key 105**: $105 \\mod 11 = 6$, but slots 6 and 7 are occupied, probe to slot 8.\n","\n","     `[ -, 100, -, 113, 114, -, 116, 117, 105, 97, 108 ]`\n","\n","   - **Key 99**: $99 \\mod 11 = 0$\n","\n","     `[ 99, 100, -, 113, 114, -, 116, 117, 105, 97, 108 ]`\n","\n","\n","3. **Final Hash Table Content**:\n","\n","   `[ 99, 100, -, 113, 114, -, 116, 117, 105, 97, 108 ]`\n","\n","\n","Here, `-` indicates an empty slot."]},{"cell_type":"markdown","metadata":{},"source":["### (12) What is the worst case scenario for the bubble sort, selection sort, insertion sort, shell sort, merge sort and quick sort?"]},{"cell_type":"markdown","metadata":{},"source":["Ans:\n","\n","The worst-case scenarios for each of these sorting algorithms vary, primarily based on the initial arrangement of the data and the specific mechanics of each algorithm. Here's a breakdown:\n","\n","1. **Bubble Sort**:\n","   - **Worst Case Scenario**: When the array is sorted in reverse order. Each element needs to be compared with all other elements and swapped many times to move it to its correct position.\n","   - **Time Complexity**: $O(n^2)$, where $n$ is the number of elements in the array.\n","\n","2. **Selection Sort**:\n","   - **Worst Case Scenario**: Regardless of the initial arrangement of the array, selection sort performs the same way because it always searches for the smallest (or largest) element to place it in the correct position.\n","   - **Time Complexity**: $O(n^2)$.\n","\n","3. **Insertion Sort**:\n","   - **Worst Case Scenario**: When the array is sorted in reverse order. This forces each new element to be compared with all previously sorted elements, thus requiring maximum comparisons and shifts.\n","   - **Time Complexity**: $O(n^2)$.\n","\n","4. **Shell Sort**:\n","   - **Worst Case Scenario**: The worst case for Shell sort is complex and depends on the gap sequence used. If the gaps do not break down the array efficiently, the performance can degrade. Generally, some sequences can lead to time complexities of about $O(n^2)$, but this can vary significantly.\n","   - **Time Complexity**: Depends on the gap sequence.\n","\n","5. **Merge Sort**:\n","   - **Worst Case Scenario**: Merge sort's performance remains consistent regardless of the initial arrangement of the elements. Its divide-and-conquer approach splits the array into halves and sorts each half independently before merging them.\n","   - **Time Complexity**: $O(n \\log n)$, which is maintained in all cases.\n","\n","6. **Quick Sort**:\n","   - **Worst Case Scenario**: When the array is already sorted (either in ascending or descending order) and the pivot is chosen as the first or last element. This scenario leads to no division of the array into balanced parts, thereby reducing quicksort to a process similar to selection sort.\n","   - **Time Complexity**: $O(n^2)$. However, by using randomized pivot selection or choosing the median as pivot, this worst case can usually be avoided, making the average complexity $O(n \\log n)$.\n","\n","These complexities indicate that while some algorithms have robust performance regardless of data arrangement (like merge sort), others are highly sensitive to input order (like bubble sort, insertion sort, and naive implementations of quick sort)."]},{"cell_type":"markdown","metadata":{},"source":["### (13) What is the best case scenario for the bubble sort, selection sort, insertion sort, shell sort, merge sort and quick sort?"]},{"cell_type":"markdown","metadata":{},"source":["The best-case scenarios for sorting algorithms often depend on the initial order of the elements and the specific design of the algorithm. Let's discuss the best-case scenarios for each of the sorting algorithms mentioned:\n","\n","1. **Bubble Sort**:\n","   - **Best Case Scenario**: When the array is already sorted in the correct order. Bubble sort will make one pass through the array, make no swaps, and terminate early if optimized with a flag to recognize sorted data.\n","   - **Time Complexity**: $O(n)$ in the best case, where $n$ is the number of elements, if optimized with a flag to detect no swaps.\n","\n","2. **Selection Sort**:\n","   - **Best Case Scenario**: The performance of selection sort does not vary with the initial order of the elements; it always performs the same number of comparisons and swaps.\n","   - **Time Complexity**: $O(n^2)$, as it always finds the minimum element and places it at the beginning regardless of the array's order.\n","\n","3. **Insertion Sort**:\n","   - **Best Case Scenario**: When the array is already sorted. Each new element needs only a single comparison to confirm its position.\n","   - **Time Complexity**: $O(n)$, making it very efficient for small or nearly sorted arrays.\n","\n","4. **Shell Sort**:\n","   - **Best Case Scenario**: As with insertion sort, a nearly sorted array or smaller size can lead to fewer comparisons and movements, even with larger gaps initially.\n","   - **Time Complexity**: Varies with the gap sequence but can approach $O(n \\log n)$ under ideal conditions with an optimal gap sequence.\n","\n","5. **Merge Sort**:\n","   - **Best Case Scenario**: Merge sort's divide and conquer approach has consistent performance regardless of the initial data arrangement.\n","   - **Time Complexity**: $O(n \\log n)$, even in the best case, as the array is always divided and merged.\n","\n","6. **Quick Sort**:\n","   - **Best Case Scenario**: When the pivot selection always results in perfect partitioning, dividing the array into equal parts. This is typically achieved when the pivot is the median value at each step.\n","   - **Time Complexity**: $O(n \\log n)$, which is achievable with good pivot selection like using the median-of-three method.\n","\n","These scenarios illustrate how the inherent design of each sorting algorithm affects its efficiency in different situations. For instance, algorithms like insertion sort dramatically benefit from initially sorted or nearly sorted data, while others like merge sort and selection sort maintain consistent time complexities regardless of initial order."]},{"cell_type":"markdown","metadata":{},"source":["### (14) Analyze the stability of the bubble sort, selection sort, insertion sort, shell sort, merge sort and quick sort.\n","\n","The stability of a sorting algorithm is an important property, especially when dealing with complex data structures where multiple records might share a key value, but differ in other attributes. A stable sorting algorithm preserves the relative order of records with equal keys. Here's an overview of the stability for each of the mentioned sorting algorithms:\n","\n","1. **Bubble Sort**:\n","   - **Stability**: Stable. Bubble sort compares each pair of adjacent items and swaps them if they are in the wrong order. Since equal elements are never swapped, their relative order remains unchanged.\n","\n","2. **Selection Sort**:\n","   - **Stability**: Unstable. The fundamental operation in selection sort is finding the minimum or maximum from the unsorted segment and placing it at the end of the sorted segment. This operation might move elements past other elements with the same key, thereby altering their relative positions.\n","\n","3. **Insertion Sort**:\n","   - **Stability**: Stable. As each element is inserted into the sorted portion of the array, it is compared only until a smaller element is found. This means equal elements are never moved past each other, preserving their original order.\n","\n","4. **Shell Sort**:\n","   - **Stability**: Unstable. Shell sort is an extension of insertion sort that allows the exchange of items that are far apart. The large gaps between elements in the early phases of the algorithm can move elements past others with the same key, disrupting their relative order.\n","\n","5. **Merge Sort**:\n","   - **Stability**: Stable. During the merge operation, if two elements from the two merged arrays are equal, the element from the left (or first) array will always be considered first. This policy ensures that the relative order of equal elements is maintained.\n","\n","6. **Quick Sort**:\n","   - **Stability**: Unstable. The partitioning step in quicksort may rearrange equal elements as it moves them around the pivot. Depending on the implementation, equal elements can end up on either side of the pivot, which changes their relative order.\n","\n","In summary, Bubble Sort, Insertion Sort, and Merge Sort are stable sorting algorithms, which makes them particularly useful when sorting data where the preservation of initial order is crucial for equal elements. On the other hand, Selection Sort, Shell Sort, and Quick Sort are generally unstable, which might be a concern in applications where such stability is needed. However, there are variations or adaptations of unstable sorts (like stable quicksort) that can achieve stability at the cost of extra memory or complexity."]},{"cell_type":"markdown","metadata":{},"source":["### (15) Analyze the space used by the bubble sort, selection sort, insertion sort, shell sort, merge sort and quick sort (optional)."]},{"cell_type":"markdown","metadata":{},"source":["The memory usage of sorting algorithms is a critical aspect, especially when handling large datasets. Here's how each of the mentioned sorting algorithms typically handles memory:\n","\n","1. **Bubble Sort**:\n","   - **Memory Usage**: In-place. Bubble sort only requires a constant amount $O(1)$ of additional memory beyond the input array itself for its operations, as it swaps elements directly in the given array.\n","\n","2. **Selection Sort**:\n","   - **Memory Usage**: In-place. Similar to bubble sort, selection sort requires only a constant amount of additional space $O(1)$ for temporary storage during the swap operation.\n","\n","3. **Insertion Sort**:\n","   - **Memory Usage**: In-place. Insertion sort also operates directly on the array and requires only a minimal constant amount of extra space $O(1)$ for the element currently being compared and inserted.\n","\n","4. **Shell Sort**:\n","   - **Memory Usage**: In-place. Shell sort, an extension of insertion sort, also requires only constant additional space $O(1)$ beyond the input array, regardless of the gap sequence used.\n","\n","5. **Merge Sort**:\n","   - **Memory Usage**: Out-of-place. Merge sort requires additional memory for its operation, typically $O(n)$, where $n$ is the number of elements to be sorted. This is because it needs to temporarily store the elements in auxiliary arrays during the merge process, doubling the memory usage compared to the input array size.\n","\n","6. **Quick Sort**:\n","   - **Memory Usage**: In-place. Quick sort generally uses $O(\\log n)$ additional space in the best or average case for the stack space required by recursion (logarithmic stack space due to the depth of the recursion used to store stack frame). In the worst case (when recursion may go $n$ levels deep), it can use $O(n)$ space.\n","\n","These descriptions provide an overview of the additional memory needed by each algorithm beyond the original array. Notably, algorithms like bubble sort, selection sort, and insertion sort are particularly memory-efficient with only $O(1)$ additional space, making them suitable for scenarios where memory is constrained. In contrast, merge sort, while excellent in terms of time complexity, requires significantly more memory, which can be a limitation in memory-sensitive environments."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM05PvnQCNZRcQoGrec0tth","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}
